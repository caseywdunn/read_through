{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codon Read Through Analysis in Drosophila\n",
    "\n",
    "This notebook analyzes codon read through in Drosophila melanogaster using transcript and CDS sequences from FlyBase.\n",
    "\n",
    "## Overview\n",
    "- Parse transcript and CDS FASTA files\n",
    "- Associate CDS with parent transcripts\n",
    "- Extract 5' UTR, ORF1, and 3' UTR regions\n",
    "- Analyze amino acid sequences, stop codons, and potential ORF2\n",
    "- Compare with externally validated readthrough candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import re\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Parse FASTA files and associate CDS with transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta_header(header):\n",
    "    \"\"\"Parse FASTA header to extract metadata.\"\"\"\n",
    "    metadata = {}\n",
    "    \n",
    "    # Extract ID (first part of header)\n",
    "    parts = header.split(' ', 1)\n",
    "    metadata['id'] = parts[0]\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        # Parse key=value pairs\n",
    "        attributes = parts[1]\n",
    "        \n",
    "        # Handle parent field which can have multiple values\n",
    "        parent_match = re.search(r'parent=([^;]+)', attributes)\n",
    "        if parent_match:\n",
    "            metadata['parent'] = parent_match.group(1).split(',')\n",
    "        \n",
    "        # Extract other fields\n",
    "        for field in ['type', 'name', 'length']:\n",
    "            match = re.search(f'{field}=([^;]+)', attributes)\n",
    "            if match:\n",
    "                metadata[field] = match.group(1)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def load_sequences(fasta_file):\n",
    "    \"\"\"Load sequences from FASTA file with parsed headers.\"\"\"\n",
    "    sequences = {}\n",
    "    \n",
    "    for record in SeqIO.parse(fasta_file, 'fasta'):\n",
    "        metadata = parse_fasta_header(record.description)\n",
    "        sequences[metadata['id']] = {\n",
    "            'sequence': str(record.seq),\n",
    "            'metadata': metadata\n",
    "        }\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "print(\"Loading transcript sequences...\")\n",
    "transcripts = load_sequences('dmel-all-transcript-r6.64.fasta')\n",
    "print(f\"Loaded {len(transcripts)} transcripts\")\n",
    "\n",
    "print(\"Loading CDS sequences...\")\n",
    "cds_sequences = load_sequences('dmel-all-CDS-r6.64.fasta')\n",
    "print(f\"Loaded {len(cds_sequences)} CDS sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example of parsed data\n",
    "transcript_id = list(transcripts.keys())[0]\n",
    "print(f\"Example transcript: {transcript_id}\")\n",
    "print(f\"Metadata: {transcripts[transcript_id]['metadata']}\")\n",
    "print(f\"Sequence length: {len(transcripts[transcript_id]['sequence'])}\")\n",
    "print()\n",
    "\n",
    "cds_id = list(cds_sequences.keys())[0]\n",
    "print(f\"Example CDS: {cds_id}\")\n",
    "print(f\"Metadata: {cds_sequences[cds_id]['metadata']}\")\n",
    "print(f\"Sequence length: {len(cds_sequences[cds_id]['sequence'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_cds_transcripts(transcripts, cds_sequences):\n",
    "    \"\"\"Associate each CDS with its parent transcript.\"\"\"\n",
    "    associations = {}\n",
    "    warnings_count = 0\n",
    "    \n",
    "    for cds_id, cds_data in cds_sequences.items():\n",
    "        if 'parent' not in cds_data['metadata']:\n",
    "            print(f\"Warning: CDS {cds_id} has no parent information\")\n",
    "            warnings_count += 1\n",
    "            continue\n",
    "            \n",
    "        parents = cds_data['metadata']['parent']\n",
    "        \n",
    "        # Find transcript parent (starts with FBtr)\n",
    "        transcript_parent = None\n",
    "        for parent in parents:\n",
    "            if parent.startswith('FBtr'):\n",
    "                transcript_parent = parent\n",
    "                break\n",
    "        \n",
    "        if not transcript_parent:\n",
    "            print(f\"Warning: CDS {cds_id} has no transcript parent\")\n",
    "            warnings_count += 1\n",
    "            continue\n",
    "            \n",
    "        if transcript_parent not in transcripts:\n",
    "            print(f\"Warning: Transcript {transcript_parent} not found for CDS {cds_id}\")\n",
    "            warnings_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Check for one-to-one mapping\n",
    "        if transcript_parent in associations:\n",
    "            print(f\"Warning: Transcript {transcript_parent} already associated with another CDS\")\n",
    "            warnings_count += 1\n",
    "            continue\n",
    "            \n",
    "        associations[transcript_parent] = cds_id\n",
    "    \n",
    "    print(f\"Successfully associated {len(associations)} CDS-transcript pairs\")\n",
    "    print(f\"Issued {warnings_count} warnings for problematic associations\")\n",
    "    \n",
    "    return associations\n",
    "\n",
    "cds_transcript_map = associate_cds_transcripts(transcripts, cds_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_cds_to_transcript(transcript_seq, cds_seq):\n",
    "    \"\"\"Align CDS to transcript and extract UTRs and ORF.\"\"\"\n",
    "    # Find CDS in transcript\n",
    "    cds_start = transcript_seq.find(cds_seq)\n",
    "    \n",
    "    if cds_start == -1:\n",
    "        return None\n",
    "    \n",
    "    cds_end = cds_start + len(cds_seq)\n",
    "    \n",
    "    # Extract regions\n",
    "    utr5 = transcript_seq[:cds_start]\n",
    "    orf1 = cds_seq\n",
    "    utr3 = transcript_seq[cds_end:]\n",
    "    \n",
    "    return {\n",
    "        'utr5': utr5,\n",
    "        'orf1': orf1,\n",
    "        'utr3': utr3,\n",
    "        'cds_start': cds_start,\n",
    "        'cds_end': cds_end\n",
    "    }\n",
    "\n",
    "def create_gene_dataframe(transcripts, cds_sequences, cds_transcript_map):\n",
    "    \"\"\"Create dataframe with gene information.\"\"\"\n",
    "    data = []\n",
    "    failed_alignments = 0\n",
    "    \n",
    "    for transcript_id, cds_id in cds_transcript_map.items():\n",
    "        transcript_seq = transcripts[transcript_id]['sequence']\n",
    "        cds_seq = cds_sequences[cds_id]['sequence']\n",
    "        \n",
    "        # Get gene ID from transcript metadata\n",
    "        gene_id = None\n",
    "        if 'parent' in transcripts[transcript_id]['metadata']:\n",
    "            for parent in transcripts[transcript_id]['metadata']['parent']:\n",
    "                if parent.startswith('FBgn'):\n",
    "                    gene_id = parent\n",
    "                    break\n",
    "        \n",
    "        if not gene_id:\n",
    "            gene_id = transcript_id  # fallback\n",
    "        \n",
    "        alignment = align_cds_to_transcript(transcript_seq, cds_seq)\n",
    "        \n",
    "        if alignment is None:\n",
    "            failed_alignments += 1\n",
    "            continue\n",
    "            \n",
    "        data.append({\n",
    "            'gene_id': gene_id,\n",
    "            'transcript_id': transcript_id,\n",
    "            'cds_id': cds_id,\n",
    "            'utr5': alignment['utr5'],\n",
    "            'orf1': alignment['orf1'],\n",
    "            'utr3': alignment['utr3']\n",
    "        })\n",
    "    \n",
    "    print(f\"Successfully processed {len(data)} genes\")\n",
    "    print(f\"Failed to align {failed_alignments} CDS sequences\")\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create the initial dataframe\n",
    "df = create_gene_dataframe(transcripts, cds_sequences, cds_transcript_map)\n",
    "print(f\"Created dataframe with {len(df)} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Add sequence analysis columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sequence(seq):\n",
    "    \"\"\"Translate nucleotide sequence to amino acids.\"\"\"\n",
    "    if len(seq) % 3 != 0:\n",
    "        seq = seq[:-(len(seq) % 3)]  # trim to multiple of 3\n",
    "    \n",
    "    bio_seq = Seq(seq)\n",
    "    return str(bio_seq.translate())\n",
    "\n",
    "def find_stop_codons(seq):\n",
    "    \"\"\"Find all stop codons in sequence.\"\"\"\n",
    "    stop_codons = ['TAA', 'TAG', 'TGA']\n",
    "    positions = []\n",
    "    \n",
    "    for i in range(0, len(seq) - 2, 3):\n",
    "        codon = seq[i:i+3]\n",
    "        if codon in stop_codons:\n",
    "            positions.append((i, codon))\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def analyze_sequences(df):\n",
    "    \"\"\"Add sequence analysis columns to dataframe.\"\"\"\n",
    "    \n",
    "    # Initialize new columns\n",
    "    df['aa_sequence_orf1'] = ''\n",
    "    df['stop_codon_orf1'] = ''\n",
    "    df['bp_after_stop'] = ''\n",
    "    df['utr3_length'] = 0\n",
    "    df['first_stop_after_canonical'] = ''\n",
    "    df['orf2_translation'] = ''\n",
    "    df['orf1_nucleotide'] = ''\n",
    "    df['orf2_nucleotide'] = ''\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        orf1 = row['orf1']\n",
    "        utr3 = row['utr3']\n",
    "        \n",
    "        # AA sequence of ORF1\n",
    "        df.at[idx, 'aa_sequence_orf1'] = translate_sequence(orf1)\n",
    "        \n",
    "        # Stop codon at end of ORF1\n",
    "        if len(orf1) >= 3:\n",
    "            df.at[idx, 'stop_codon_orf1'] = orf1[-3:]\n",
    "        \n",
    "        # Base pairs following the stop (start of 3' UTR)\n",
    "        df.at[idx, 'bp_after_stop'] = utr3[:10] if len(utr3) >= 10 else utr3\n",
    "        \n",
    "        # Length of 3' UTR\n",
    "        df.at[idx, 'utr3_length'] = len(utr3)\n",
    "        \n",
    "        # Find first stop codon in 3' UTR (potential ORF2 end)\n",
    "        stop_positions = find_stop_codons(utr3)\n",
    "        if stop_positions:\n",
    "            df.at[idx, 'first_stop_after_canonical'] = stop_positions[0][1]\n",
    "            orf2_end = stop_positions[0][0] + 3\n",
    "        else:\n",
    "            df.at[idx, 'first_stop_after_canonical'] = ''\n",
    "            orf2_end = len(utr3)\n",
    "        \n",
    "        # ORF2 sequences (starting immediately after ORF1 stop codon)\n",
    "        orf2_seq = utr3[:orf2_end]\n",
    "        df.at[idx, 'orf2_nucleotide'] = orf2_seq\n",
    "        \n",
    "        # Translate ORF2\n",
    "        if orf2_seq:\n",
    "            df.at[idx, 'orf2_translation'] = translate_sequence(orf2_seq)\n",
    "        \n",
    "        # ORF1 nucleotide sequence\n",
    "        df.at[idx, 'orf1_nucleotide'] = orf1\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply sequence analysis\n",
    "df = analyze_sequences(df)\n",
    "print(\"Added sequence analysis columns\")\n",
    "print(f\"Dataframe now has {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some examples of the analysis\n",
    "print(\"Sample of sequence analysis:\")\n",
    "sample_cols = ['gene_id', 'stop_codon_orf1', 'utr3_length', 'first_stop_after_canonical', 'orf2_translation']\n",
    "print(df[sample_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Add readthrough validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_readthrough_candidates(filename):\n",
    "    \"\"\"Load externally validated readthrough candidates.\"\"\"\n",
    "    readthrough_genes = set()\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    # Extract gene ID (assuming it's the first column or contains FBgn)\n",
    "                    parts = line.split('\\t')\n",
    "                    for part in parts:\n",
    "                        if 'FBgn' in part:\n",
    "                            readthrough_genes.add(part.strip())\n",
    "                            break\n",
    "                    else:\n",
    "                        # If no FBgn found, try first column\n",
    "                        if parts:\n",
    "                            readthrough_genes.add(parts[0].strip())\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {filename} not found\")\n",
    "        return set()\n",
    "    \n",
    "    return readthrough_genes\n",
    "\n",
    "# Load readthrough candidates\n",
    "readthrough_candidates = load_readthrough_candidates('Data1_DmelReadthroughCandidates.txt')\n",
    "print(f\"Loaded {len(readthrough_candidates)} readthrough candidates\")\n",
    "\n",
    "# Show first few candidates\n",
    "print(\"First 10 readthrough candidates:\")\n",
    "for i, candidate in enumerate(list(readthrough_candidates)[:10]):\n",
    "    print(f\"  {candidate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add readthrough column to dataframe\n",
    "df['has_readthrough'] = df['gene_id'].isin(readthrough_candidates)\n",
    "\n",
    "print(f\"Genes with validated readthrough: {df['has_readthrough'].sum()}\")\n",
    "print(f\"Total genes in analysis: {len(df)}\")\n",
    "print(f\"Percentage with readthrough: {df['has_readthrough'].sum() / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataframe overview\n",
    "print(\"Final dataframe columns:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  {col}\")\n",
    "\n",
    "print(f\"\\nDataframe shape: {df.shape}\")\n",
    "\n",
    "# Show complete example\n",
    "print(\"\\nComplete example (first readthrough gene):\")\n",
    "readthrough_example = df[df['has_readthrough']].iloc[0] if df['has_readthrough'].any() else df.iloc[0]\n",
    "for col, val in readthrough_example.items():\n",
    "    if isinstance(val, str) and len(val) > 50:\n",
    "        print(f\"{col}: {val[:50]}...\")\n",
    "    else:\n",
    "        print(f\"{col}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic analysis of readthrough genes\n",
    "print(\"Analysis of genes with readthrough:\")\n",
    "readthrough_df = df[df['has_readthrough']]\n",
    "\n",
    "if len(readthrough_df) > 0:\n",
    "    print(f\"Average 3' UTR length in readthrough genes: {readthrough_df['utr3_length'].mean():.1f} bp\")\n",
    "    print(f\"Average 3' UTR length in non-readthrough genes: {df[~df['has_readthrough']]['utr3_length'].mean():.1f} bp\")\n",
    "    \n",
    "    print(f\"\\nStop codons in readthrough genes:\")\n",
    "    print(readthrough_df['stop_codon_orf1'].value_counts())\n",
    "    \n",
    "    print(f\"\\nStop codons in non-readthrough genes:\")\n",
    "    print(df[~df['has_readthrough']]['stop_codon_orf1'].value_counts())\n",
    "    \n",
    "    # Genes with potential ORF2 (have stop codon in 3' UTR)\n",
    "    has_orf2 = readthrough_df['first_stop_after_canonical'] != ''\n",
    "    print(f\"\\nReadthrough genes with potential ORF2: {has_orf2.sum()} / {len(readthrough_df)}\")\n",
    "else:\n",
    "    print(\"No readthrough genes found in the analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final dataframe\n",
    "df.to_csv('drosophila_readthrough_analysis.csv', index=False)\n",
    "print(\"Saved analysis results to 'drosophila_readthrough_analysis.csv'\")\n",
    "\n",
    "# Save summary statistics\n",
    "with open('analysis_summary.txt', 'w') as f:\n",
    "    f.write(\"Drosophila Readthrough Analysis Summary\\n\")\n",
    "    f.write(\"=====================================\\n\\n\")\n",
    "    f.write(f\"Total genes analyzed: {len(df)}\\n\")\n",
    "    f.write(f\"Genes with validated readthrough: {df['has_readthrough'].sum()}\\n\")\n",
    "    f.write(f\"Percentage with readthrough: {df['has_readthrough'].sum() / len(df) * 100:.2f}%\\n\\n\")\n",
    "    \n",
    "    if df['has_readthrough'].any():\n",
    "        readthrough_df = df[df['has_readthrough']]\n",
    "        f.write(f\"Average 3' UTR length (readthrough): {readthrough_df['utr3_length'].mean():.1f} bp\\n\")\n",
    "        f.write(f\"Average 3' UTR length (non-readthrough): {df[~df['has_readthrough']]['utr3_length'].mean():.1f} bp\\n\")\n",
    "        \n",
    "        has_orf2 = readthrough_df['first_stop_after_canonical'] != ''\n",
    "        f.write(f\"Readthrough genes with potential ORF2: {has_orf2.sum()} / {len(readthrough_df)}\\n\")\n",
    "\n",
    "print(\"Saved summary to 'analysis_summary.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
